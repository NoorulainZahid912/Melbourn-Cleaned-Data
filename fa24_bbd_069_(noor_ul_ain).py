# -*- coding: utf-8 -*-
"""FA24-BBD-069 (Noor-Ul-Ain).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KZfHcf4XYGl3re9vJzrCibc87JWXmm1G
"""

import pandas as pd
import numpy as np

df=pd.read_csv("melb_data.csv")
df.head()

"""# (1) Handling Missing Values

# **1)   Identifying Columns with more than 20% missing values and Dropping them**
"""

missing_person=(df.isna().sum()/len(df))*100
Dropped_columns=missing_person[missing_person>20].index
print("Following are the columns with more than 20% missing Values: ")
print(Dropped_columns)
df=df.drop(columns=Dropped_columns)
print("Congrats! Columns with missing values have been dropped. ")
df.head()

"""# **2)Filling values in Numeric Columns using median**"""

df.fillna(df.median(numeric_only=True),inplace=True)
df.head()

"""# **3) Filling Values in Categorical columns using Mode**"""

Categorical_columns=df.select_dtypes(include=['object']).columns
for column in Categorical_columns:
    frequent_values=df[column].mode()
    if not frequent_values.empty:
        df[column]=df[column].fillna(frequent_values[0])
df.head()

"""# (2)  ADVANCED FILTERING AND INDEXING

## **1)	Retrieve all properties located in "Richmond" with a price greater than  1,000,000.**
"""

# Extracting the data of properties located in Richmond with a price greater than 1,000,000.
Richmond_Houses = df[(df["Suburb"]=="Richmond") & (df["Price"]>1000000)]
Richmond_Houses.head()

"""#  **2)Extracting the specific columns where the land size is above 500 sq.meter**

*Note: "AS WE HAVE ALREADY DROPPED COLUMNS WITH MORE THAN 20% MISSING VALUES SO (BUILDINGAREA) COLUMN IS ALREADY DROPPED!"*

"""

# Extracting the specific columns where the land size is above 500 sq.meter
if "BuildindArea" in df.columns:
    df_filtered=df.loc[df["Landsize"] > 500 , ["Price","Suburb","BuildingArea"]]
else:
    print("BuildingArea column is Not Present! ^_^ ")
    df_filtered=df.loc[df["Landsize"] >  500 , ["Price","Suburb"]]
df_filtered.head()

"""# **3)	Finding the top 5 most expensive houses in the dataset using sorting**"""

df_Expensive_houses = df.sort_values(by="Price",ascending=False)
df_Expensive_houses.head()

"""# (3) Data Transformation and Feachered Engineering:

# **1) Creating a new column that calculates the price per room**
"""

df["Price_per_Room"] = df["Price"] / df["Rooms"].astype(int)
pd.set_option("display.float_format","{:.0f}".format)
df.head()

"""
# **2) Converting Date column into proper date time format**"""

df["Date"] = pd.to_datetime(df["Date"], format = "%d/%m/%Y")
df.head()

"""# **3)	Extracting the year of sale from the date and create a new column Year_Sold**"""

df["Year_sold"] = df["Date"].dt.year
df.head()

"""#                  (4) Aggregation and Grouping

## **1) Average price of properties in each Suburb**
"""

Suburb_average_price = df.groupby("Suburb")["Price"].mean()
print(Suburb_average_price)

"""# **2) Finding the total number of properties sold in each suburb.**"""

Properties_per_Suburb = df.groupby("Suburb")["Price"].count()
print(Properties_per_Suburb)

"""
## **3) Identifying Suburb with the highest average price.**"""

Most_Expensive_Suburb = Suburb_average_price.idxmax()
print(f"This is the  most expensive Suburb : {Most_Expensive_Suburb} ")

"""# **Creating new column of Category for identifying houses as Expensive or Affordable**"""

df["Category"] = ["Expensive" if price > df["Price"].median() else "Affordable" for price in df["Price"]]
df.head()

"""# **Finding correlation between Rooms and their Prices**"""

print(df[["Rooms","Price"]].corr())

df.to_csv("cleaned_melb_data.csv", index=False)

import matplotlib.pyplot as plt
Suburb_average_price.head(10).plot(kind="bar")
plt.title("(^_^) Average Houses Prices in top 10 Suburbs")
plt.xlabel("Suburb")

!pip install visions==0.7.6 --use-deprecated=legacy-resolver

!pip install --upgrade numba --use-deprecated=legacy-resolver

!pip install ydata-profiling --use-deprecated=legacy-resolver

#from google.colab import drive
drive.mount('/content/drive')
# This command is only used if you want to connect GOogle Drive

from ydata_profiling import ProfileReport

profile = ProfileReport(df, title="Pandas Profiling Report")
profile.to_notebook_iframe()